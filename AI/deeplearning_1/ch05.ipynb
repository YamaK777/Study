{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "from dataset.mnist import load_mnist\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重みパラメータの損失関数の勾配を数値微分で調べた\n",
    "# 計算に時間がかかる\n",
    "# 誤差逆伝播法\n",
    "# 計算グラフで理解する\n",
    "# リンゴ１個１２０円で消費税１０％で２個買う\n",
    "# １２０ * ２ * １.１ ＝ ２２０\n",
    "# これを→に順番で計算する：順当\n",
    "# 答えありきで考える：←から考える\n",
    "# 連鎖律：合成関数　y = f(u),u = g(x)を微分\n",
    "# y' = f'(g(x))\n",
    "# y'/x' = y'/u'*u'/x':これで約分する。\n",
    "# さっきのやつをむずく\n",
    "# x↘　ｔ\n",
    "# 　+ → * → z\n",
    "# y↗　l↗\n",
    "# 基本は\n",
    "# ｘ　ｙ\n",
    "# → F →\n",
    "# 順　ｙ = F(x)\n",
    "# 逆　L/y' = F'(x)/x' L:上流から来た値 or 出力値\n",
    "# 乗算は入力の逆の値をかけたものが出ていく→z = t*l→ｔのルートならtで微分→z' = l\n",
    "# 加算はそのまま出ていく→ x+yをxで微分 →　1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 逆伝播まとめ\n",
    "# 基本は入力で出力を微分\n",
    "# 加算：x+yをxで微分 →　1\n",
    "# 乗算:z = t*l→ｔのルートならtで微分→z' = l\n",
    "\n",
    "# 微分のテンプレ要確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 乗算クラス\n",
    "class MulLayer:\n",
    "# コンストラクタでインスタンス変数を定義\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "# 順伝播\n",
    "    def forward(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y                \n",
    "        out = x * y\n",
    "\n",
    "        return out\n",
    "# 逆伝播、dout:上流から微分してきたもの\n",
    "    def backward(self, dout):\n",
    "        dx = dout * self.y # 来た方と逆のものがかけられてる\n",
    "        dy = dout * self.x\n",
    "\n",
    "        return dx, dy\n",
    "# ここで作ったのが各層(レイヤ)で使うものの一部\n",
    "# シグモイド関数とか配列の積を足し合わせてできたものを層という"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220.00000000000003\n",
      "price: 220\n",
      "dApple: 2.2\n",
      "dApple_num: 110\n",
      "dTax: 200\n"
     ]
    }
   ],
   "source": [
    "# 例\n",
    "apple = 100\n",
    "apple_num = 2\n",
    "tax = 1.1\n",
    "\n",
    "# 乗算クラスのオブジェクト生成\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "\n",
    "# forward順伝播\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)\n",
    "price = mul_tax_layer.forward(apple_price, tax)\n",
    "\n",
    "# backward逆伝播\n",
    "dprice = 1\n",
    "dapple_price, dtax = mul_tax_layer.backward(dprice)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
    "\n",
    "# intつけないとこうなる→少数をうまく2進数化できない\n",
    "# https://blog.apar.jp/program/8900/\n",
    "print(price)\n",
    "print(\"price:\", int(price))\n",
    "print(\"dApple:\", dapple)\n",
    "print(\"dApple_num:\", int(dapple_num))\n",
    "print(\"dTax:\", dtax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加算クラス\n",
    "class AddLayer:\n",
    "# コンストラクタ：何もしない\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        out = x + y\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = dout * 1\n",
    "        dy = dout * 1\n",
    "\n",
    "        return dx, dy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price: 715\n",
      "dApple: 2.2\n",
      "dApple_num: 110\n",
      "dOrange: 3.3\n",
      "dOrange_num: 165\n",
      "dTax: 650\n"
     ]
    }
   ],
   "source": [
    "# 例\n",
    "apple = 100\n",
    "apple_num = 2\n",
    "orange = 150\n",
    "orange_num = 3\n",
    "tax = 1.1\n",
    "\n",
    "# 乗算・加算クラスのオブジェクト生成\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_orange_layer = MulLayer()\n",
    "add_apple_orange_layer = AddLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "\n",
    "# forward順伝播\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)  # (1)\n",
    "orange_price = mul_orange_layer.forward(orange, orange_num)  # (2)\n",
    "all_price = add_apple_orange_layer.forward(apple_price, orange_price)  # (3)\n",
    "price = mul_tax_layer.forward(all_price, tax)  # (4)\n",
    "\n",
    "# backward逆伝播\n",
    "dprice = 1\n",
    "dall_price, dtax = mul_tax_layer.backward(dprice)  # (4)\n",
    "dapple_price, dorange_price = add_apple_orange_layer.backward(dall_price)  # (3)\n",
    "dorange, dorange_num = mul_orange_layer.backward(dorange_price)  # (2)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)  # (1)\n",
    "dorange *=10 # 整数にする\n",
    "dorange /=10 # そのあと少数に→これで上記の誤差が出なくなる\n",
    "\n",
    "print(\"price:\", int(price))\n",
    "print(\"dApple:\", dapple)\n",
    "print(\"dApple_num:\", int(dapple_num))\n",
    "print(\"dOrange:\", dorange)\n",
    "print(\"dOrange_num:\", int(dorange_num))\n",
    "print(\"dTax:\", dtax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 活性化関数を実装\n",
    "# Reluクラス\n",
    "# 入力が規定値(0)より大きいなら入力値 = 出力値\n",
    "# それ以外は出ない\n",
    "class Relu:\n",
    "# コンストラクタで初期値設定\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x):\n",
    "# True/Falseが格納(xが規定値以下)\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "# 規定値以下は0に\n",
    "# Trueのところは0にする\n",
    "        out[self.mask] = 0\n",
    "\n",
    "        return out\n",
    "# 逆伝播も同じ\n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 思考過程は要復習\n",
    "# シグモイド関数\n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = 1 / (1 + np.exp(-x))\n",
    "        self.out = out\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = dout * (1.0 - self.out) * self.out\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 今までのはスカラ値\n",
    "# 行列で考えよう\n",
    "# 入力と重み、バイアスは行列\n",
    "# 行列の積とか加算どうやる？\n",
    "# 行列の積をアフィン変換という\n",
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W =W\n",
    "        self.b = b\n",
    "        \n",
    "        self.x = None\n",
    "        self.original_x_shape = None\n",
    "        # 重み・バイアスパラメータの微分\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # テンソル対応\n",
    "        self.original_x_shape = x.shape\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        self.x = x\n",
    "\n",
    "        out = np.dot(self.x, self.W) + self.b\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        \n",
    "        dx = dx.reshape(*self.original_x_shape)  # 入力データの形状に戻す（テンソル対応）\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力→アフィン→ReLU→…→Softmax→出力って感じ\n",
    "# 学習の時はsofmax使うけど\n",
    "# 推論の時は使わんch02の時\n",
    "# ソフトマックス関数と損失関数(交差エントロピー誤差)を含めた層を作る\n",
    "# ソフトマック関数の逆伝播は(出力-教師データ)で出ていく\n",
    "# ねらってやっているらしい\n",
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None\n",
    "        self.y = None # softmaxの出力\n",
    "        self.t = None # 教師データ\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        \n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "# https://qiita.com/segavvy/items/8707e4e65aa7fa357d8a\n",
    "# バッチ版の順伝播では最後に交差エントロピー誤差を合計して、バッチの個数（batch_size）で割って1つの値にしている\n",
    "# 逆伝播ではひっくり返しが入る\n",
    "         dx = (self.y - self.t) / batch_size\n",
    "#         if self.t.size == self.y.size: # 教師データがone-hot-vectorの場合\n",
    "#             dx = (self.y - self.t) / batch_size\n",
    "#         else:\n",
    "#             dx = self.y.copy()\n",
    "#             dx[np.arange(batch_size), self.t] -= 1\n",
    "#             dx = dx / batch_size\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 復習\n",
    "# 学習の手順\n",
    "# ミニバッチつくって推論→損失関数\n",
    "# 損失関数の勾配を算出\n",
    "# 各パラメータを勾配方向に更新\n",
    "# 上記を繰り返す\n",
    "\n",
    "# 例（２層のニューラルネットワーク）\n",
    "class TwoLayerNet:\n",
    "# コンストラクタ\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std = 0.01):\n",
    "        # 重みの初期化\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size) \n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "\n",
    "        # レイヤの生成\n",
    "#       順番付きディクショナリ\n",
    "# これに格納すれば追加した順にアフィンの順伝播を逆伝播は逆順にとできる\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\n",
    "\n",
    "        self.lastLayer = SoftmaxWithLoss()\n",
    "# 推論\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "# 損失関数x:入力データ, t:教師データ\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.lastLayer.forward(y, t)\n",
    "# 認識精度\n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "        \n",
    "# 各パラメータの損失関数の勾配(数値微分)x:入力データ, t:教師データ\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads\n",
    "# 逆差逆伝搬法での各パラメータの損失関数の勾配\n",
    "    def gradient(self, x, t):\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout)\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 設定\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1:3.4739176175192574e-10\n",
      "b1:1.8015506556370333e-09\n",
      "W2:5.525015979367229e-09\n",
      "b2:1.4028682551736615e-07\n"
     ]
    }
   ],
   "source": [
    "# 数値微分と解析的(誤差逆伝播法)での計測\n",
    "# 数値微分：処理が重い\n",
    "# 解析的：実装が複雑\n",
    "# 解析的がうまくいってるか確認したいときに数値微分をつかう\n",
    "# 誤差逆伝播法と数値微分の勾配の差を確認すること→勾配確認\n",
    "# データの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "x_batch = x_train[:3]\n",
    "t_batch = t_train[:3]\n",
    "\n",
    "# 数値微分\n",
    "grad_numerical = network.numerical_gradient(x_batch, t_batch)\n",
    "# 誤差逆伝播法\n",
    "grad_backprop = network.gradient(x_batch, t_batch)\n",
    "\n",
    "# 各重みの絶対誤差の平均を求める\n",
    "for key in grad_numerical.keys():\n",
    "    diff = np.average( np.abs(grad_backprop[key] - grad_numerical[key]) )\n",
    "    print(key + \":\" + str(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09675 0.0972\n",
      "0.9022166666666667 0.9048\n",
      "0.92115 0.9217\n",
      "0.9333833333333333 0.9336\n",
      "0.9411166666666667 0.9412\n",
      "0.9487 0.947\n",
      "0.95445 0.9519\n",
      "0.9607333333333333 0.9572\n",
      "0.9634333333333334 0.9588\n",
      "0.967 0.9625\n",
      "0.9692166666666666 0.9626\n",
      "0.97085 0.9646\n",
      "0.97325 0.9668\n",
      "0.9748333333333333 0.9667\n",
      "0.9765166666666667 0.9681\n",
      "0.9782833333333333 0.9685\n",
      "0.9793833333333334 0.9699\n",
      "[更新数]9999 [損失関数の値]0.0603 [訓練データの認識精度]0.9794 [テストデータの認識精度]0.9699\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (10000,) and (17,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-eac3acc77a63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[0mx2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_acc_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train acc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'test acc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'--'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"epochs\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2838\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2839\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2840\u001b[1;33m     return gca().plot(\n\u001b[0m\u001b[0;32m   2841\u001b[0m         \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2842\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1741\u001b[0m         \"\"\"\n\u001b[0;32m   1742\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1743\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1744\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[0;32m    400\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[0;32m    401\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (10000,) and (17,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 誤差逆伝播法での学習コード\n",
    "# データの読み込み\n",
    "# 訓練・教師画像、訓練・教師ラベル取得\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "# ２層ニューラルネットの構成(入力28*28、隠れ層適当、出力0～9)\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "optomizer = SGD()\n",
    "\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 勾配\n",
    "    #grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    grad = network.gradient(x_batch, t_batch)\n",
    "    \n",
    "    # 更新\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(train_acc, test_acc)\n",
    "        \n",
    "        \n",
    "        \n",
    "# 経過表示\n",
    "print(f\"[更新数]{i: >4} [損失関数の値]{loss:.4f} \"f\"[訓練データの認識精度]{train_acc:.4f} [テストデータの認識精度]{test_acc:.4f}\")\n",
    "\n",
    "# 損失関数の値の推移を描画\n",
    "x = np.arange(len(train_loss_list))\n",
    "plt.plot(x, train_loss_list, label='loss')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlim(left=0)\n",
    "plt.ylim(bottom=0)\n",
    "plt.show()\n",
    "\n",
    "# 訓練データとテストデータの認識精度の推移を描画\n",
    "x2 = np.arange(len(train_acc_list))\n",
    "plt.plot(x2, train_acc_list, label='train acc')\n",
    "plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlim(left=0)\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCD:\n",
    "    def __init__(self,lr=0.01):\n",
    "        self.lr = lr\n",
    "    \n",
    "    def update(self,params,grads):\n",
    "        for key in params.keys():\n",
    "            params[key] -= self.lr * grads[key]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
