{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# いろんな関数を登録したクラス\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pylab as plt\n",
    "# datasetフォルダのmnistファイルを開いて　load_ministメソッドをインポート\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # パスに親ディレクトリ追加\n",
    "from dataset.mnist import load_mnist\n",
    "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
    "from dataset.mnist import load_mnist\n",
    "from common.gradient import numerical_gradient\n",
    "from common.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 何が正しいかの指標を決める必要がある\n",
    "# ニュートラルネットでの指標は損失関数で考える\n",
    "# 一般的に２乗和誤差や交差エントロピー誤差を使う\n",
    "# 損失関数は性能がどれだけ「悪いか」を図る\n",
    "# その中で一番ましな（性能の悪さが最小）所→一番いいとこになる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ２乗和誤差メソッド\n",
    "# def sum_squared_error(y,t):\n",
    "#     return 0.5 * np.sum((y-t)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交差エントロピー誤差メソッド\n",
    "def cross_entropy_error(y,t):\n",
    "# y=0になったときに無限になるのを防ぐ用\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t * np.log(y + delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09750000000000003"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 正解を選ぶ\n",
    "# 正解ラベルを1、そのほかを0で→one-hot表現\n",
    "t = [0,0,1,0,0,0,0,0,0,0]\n",
    "# 出てきたパーセンテージ(ちゃんと正解に近い)\n",
    "y = [0.1,0.05,0.6,0.0,0.05,0.1,0.0,0.1,0.0,0.0]\n",
    "\n",
    "sum_squared_error(np.array(y),np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5975"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 出てきたパーセンテージ(不正解を選んだ)\n",
    "y = [0.1,0.05,0.1,0.0,0.05,0.1,0.0,0.6,0.0,0.0]\n",
    "\n",
    "sum_squared_error(np.array(y),np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.510825457099338"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 正解を選ぶ\n",
    "# 正解ラベルを1、そのほかを0で→one-hot表現\n",
    "t = [0,0,1,0,0,0,0,0,0,0]\n",
    "# 交差エントロピー誤差でone-hotを使うと\n",
    "# 正解のところだけを計算することになる\n",
    "# 出力の結果によって答えが出る\n",
    "\n",
    "# 出てきたパーセンテージ(ちゃんと正解に近い)\n",
    "y = [0.1,0.05,0.6,0.0,0.05,0.1,0.0,0.1,0.0,0.0]\n",
    "\n",
    "cross_entropy_error(np.array(y),np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.302584092994546"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 出てきたパーセンテージ(不正解を選んだ)\n",
    "y = [0.1,0.05,0.1,0.0,0.05,0.1,0.0,0.6,0.0,0.0]\n",
    "\n",
    "cross_entropy_error(np.array(y),np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ミニバッチ学習\n",
    "# データごとに損失関数を出してその平均をとる（正規化）→それでよさげなやつを探す\n",
    "# 数ある中からランダムに１００枚取得して損失関数を出すこと"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 10)\n",
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# データ画像と正解のセットの入手\n",
    "(x_train,t_train),(x_test,t_test) = load_mnist(one_hot_label=True,normalize=True)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(t_test.shape)\n",
    "print(t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ランダムの手法\n",
    "# データ数\n",
    "train_size = x_train.shape[0]\n",
    "# ランダムに取得する数\n",
    "batch_size = 10\n",
    "# データ数からランダムに添字を決める\n",
    "batch_mask = np.random.choice(train_size,batch_size)\n",
    "# 決めたところの画像、正解を取得\n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# バッチ対応交差エントロピー誤差メソッド(one-hot版)\n",
    "def cross_entropy_error2(y,t):\n",
    "#   データが１次元配列→１つの時\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1,t.size)\n",
    "        y = y.reshape(1,y.size)\n",
    "#   データの縦の数\n",
    "    batch_size = y.shape[0]\n",
    "    \n",
    "    return -np.sum(t * np.log(y + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# バッチ対応交差エントロピー誤差メソッド\n",
    "def cross_entropy_error3(y,t):\n",
    "#   データが１次元配列→１つの時\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1,t.size)\n",
    "        y = y.reshape(1,y.size)\n",
    "        \n",
    "#   データの縦の数\n",
    "    batch_size = y.shape[0]\n",
    "#   np.arange(batch_size),tは\n",
    "#   num[np.arange(batch_size)][t] でその行で正解の出力を取り出してる\n",
    "# 　np.arange(batch_size)でbatch_size-1個の数値(配列)を生成してる\n",
    "    return -np.sum(np.log(y[np.arange(batch_size),t] + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# こう動かすんじゃね？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# シグモイド関数　２クラス分類問題で使う\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ソフトマックス関数・修正版\n",
    "def softmax(a):\n",
    "#     入力の最大値\n",
    "    c = np.max(a)\n",
    "    # 指数関数(オーバーフロー対策)\n",
    "    exp_a=np.exp(a-c)\n",
    "    # 指数関数の和\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "#   指数関数　/  指数関数の和\n",
    "    y = exp_a / sum_exp_a\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習済みの重み、バイアスがはいってるデータsample_weight.pklを読み込み\n",
    "def init_network():\n",
    "    with open(\"sample_weight.pkl\", 'rb') as f:\n",
    "       network = pickle.load(f)\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  入力から出力までを一括にする\n",
    "def predict(network, x):\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "\n",
    "    a1 = np.dot(x, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2, W3) + b3\n",
    "    y = softmax(a3)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.39570518732071"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = predict(init_network(),x_batch)\n",
    "# one-hot版\n",
    "cross_entropy_error2(y,t_ba\n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     tch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 非one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ画像と正解のセットの入手\n",
    "(x2_train,t2_train),(x2_test,t2_test) = load_mnist(one_hot_label=False,normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ランダムの手法\n",
    "# データ数\n",
    "train_size = x2_train.shape[0]\n",
    "# ランダムに取得する数\n",
    "batch_size = 10\n",
    "# データ数からランダムに添字を決める\n",
    "batch_mask = np.random.choice(train_size,batch_size)\n",
    "# 決めたところの画像、正解を取得\n",
    "x2_batch = x2_train[batch_mask]\n",
    "t2_batch = t2_train[batch_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9825286865234375"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2 = predict(init_network(),x2_batch)\n",
    "cross_entropy_error3(y2,t2_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数値微分\n",
    "# 差分で求めること\n",
    "# 悪いパターン\n",
    "# 前方差分\n",
    "# 小数点が小さすぎると「丸め誤差」がでて数値が省略される\n",
    "def numerical_diff_bad(f, x):\n",
    "    h = 1e-50 # 0.000…1小数点50以下\n",
    "    return (f(x+h) - f(x)) / h\n",
    "\n",
    "np.float32(1e-50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-04"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 中心差分\n",
    "# 使われるパターン\n",
    "def numerical_diff(f, x):\n",
    "    h = 1e-4 # 0.0001\n",
    "    return (f(x+h) - f(x-h)) / (2*h)\n",
    "\n",
    "np.float32(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 接線メソッド\n",
    "def tangent_line(f, x):\n",
    "# 傾きを求めてる\n",
    "    d = numerical_diff(f, x)\n",
    "    print(d)\n",
    "# 切片を求めてる f(x) = dx + b →  b = f(x) - dx\n",
    "    y = f(x) - d*x\n",
    "# tに接線の式を代入してる\n",
    "    return lambda t: d*t + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数式の展開で微分する\n",
    "# 「解析的～」という"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数値微分の例１\n",
    "def function_1(x):\n",
    "    return 0.01*x**2 + 0.1*x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2999999999986347\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(0.0, 20.0, 0.1)\n",
    "y = function_1(x)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "\n",
    "tf = tangent_line(function_1, 10)\n",
    "y2 = tf(x)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.plot(x, y2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 偏微分\n",
    "# 一例\n",
    "def function_2(x):\n",
    "    return x[0]**2 + x[1]**2\n",
    "# またはnp.sum(x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 偏微分のメソッド\n",
    "# すべての変数を偏微分をベクトルとしてまとめたものを「勾配」\n",
    "# 勾配を図で示すと各地点において低くなるほうに向く→遠ければ遠いほど矢印も大きくなる\n",
    "# よくない例\n",
    "def numerical_gradient_no_batch(f, x):\n",
    "    h = 1e-4  # 0.0001\n",
    "#  xと同じ形状の配列を生成→全部０\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    for idx in range(x.size):\n",
    "        tmp_val = x[idx]\n",
    "# 　　　f(x+h)の計算\n",
    "        x[idx] = float(tmp_val) + h\n",
    "        fxh1 = f(x)  # f(x+h)\n",
    "\n",
    "# 　　　f(x-h)の計算\n",
    "        x[idx] = tmp_val - h \n",
    "        fxh2 = f(x)  # f(x-h)\n",
    "\n",
    "# 　　　接点を求めてる\n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        x[idx] = tmp_val  # 値を元に戻す\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 0.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numerical_gradient_no_batch(function_2,np.array([3.0,4.0]))\n",
    "# numerical_gradient_no_batch(function_2,np.array([0.0,2.0]))\n",
    "numerical_gradient_no_batch(function_2,np.array([3.0,0.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 勾配法\n",
    "# 損失関数は複雑で重み・バイアスはパターンが多い\n",
    "# 鞍点：極値ではない点\n",
    "# 最小値：一番小さい数値\n",
    "# 極小値：一番小さくないけど、傾きは０\n",
    "# http://www.thothchildren.com/chapter/5b4084c3103f2f3168708e1f\n",
    "# ヘッセ行列で判定するのが定石？\n",
    "\n",
    "# 勾配出す→その方向に一定値すすむ→繰り返す→ベクトルが減ってくるが定石らしい\n",
    "# 勾配降下・上昇法があるけど関係ない\n",
    "# 一定値：学習率→自分で決める、正しく学習できてるか値を逐次変更するひつようあり"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 勾配降下法\n",
    "# f:最適化したい関数\n",
    "# init_x:初期値\n",
    "# lr:learning rate 学習率→ハイパーパラメータ\n",
    "# ハイパーパラメータ：人力でいい感じの数値を見つけるもの\n",
    "# step_num:勾配法の繰り返し数\n",
    "def gradient_descent(f, init_x, lr=0.01, step_num=100):\n",
    "    x = init_x\n",
    "    \n",
    "    for i in range(step_num):\n",
    "\n",
    "        grad = numerical_gradient_no_batch(f, x)\n",
    "        x -= lr * grad\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 描画してくれる\n",
    "def gradient_descent_draw(f, init_x, lr=0.01, step_num=100):\n",
    "    x = init_x\n",
    "    x_history = []\n",
    "\n",
    "    for i in range(step_num):\n",
    "        x_history.append( x.copy() )\n",
    "\n",
    "        grad = numerical_gradient_no_batch(f, x)\n",
    "        x -= lr * grad\n",
    "\n",
    "    return x, np.array(x_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 例:function_2\n",
    "init_x = np.array([-3.0,4.0])\n",
    "lr = 0.01\n",
    "step_num = 100\n",
    "x, x_history = gradient_descent_draw(function_2, init_x, lr=lr, step_num=step_num)\n",
    "\n",
    "plt.plot( [-5, 5], [0,0], '--b')\n",
    "plt.plot( [0,0], [-5, 5], '--b')\n",
    "plt.plot(x_history[:,0], x_history[:,1], 'o')\n",
    "\n",
    "plt.xlim(-3.5, 3.5)\n",
    "plt.ylim(-4.5, 4.5)\n",
    "plt.xlabel(\"X0\")\n",
    "plt.ylabel(\"X1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重みにも損失関数の勾配が必要\n",
    "# 簡易に勾配を求めるメソッド\n",
    "class simpleNet:\n",
    "# コンストラクタ\n",
    "    def __init__(self):\n",
    "#  ガウス分布に従うランダムな数値で初期化(２*３)の配列：平均0、分散1（標準偏差1）\n",
    "# 重み1個\n",
    "        self.W = np.random.randn(2,3)\n",
    "\n",
    "# 予測メソッド\n",
    "    def predict(self,x):\n",
    "# 積(左*右)\n",
    "        return np.dot(x,self.W)\n",
    "\n",
    "# 損失関数の値を求めるメソッド\n",
    "    def loss(self,x,t):\n",
    "        z = self.predict(x)\n",
    "        y = softmax(z)\n",
    "        loss = cross_entropy_error(y,t)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.77255574 -1.69785042  0.26353103]\n",
      " [-0.35405155 -0.24486828 -0.82130026]]\n"
     ]
    }
   ],
   "source": [
    "net = simpleNet()\n",
    "# 重みパラメータ\n",
    "print(net.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.78217984 -1.2390917  -0.58105162]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([0.6,0.9])\n",
    "p = net.predict(x)\n",
    "print(p)\n",
    "# 最大値のインデックス\n",
    "np.argmax(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8482997844980682"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 正解ラベル\n",
    "t = np.array([0,0,1])\n",
    "net.loss(x,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.21008268  0.13303195 -0.34311463]\n",
      " [ 0.31512402  0.19954792 -0.51467195]]\n"
     ]
    }
   ],
   "source": [
    "# ダミー用\n",
    "def f(W):\n",
    "    return net.loss(x,t)\n",
    "\n",
    "dW = numerical_gradient(f ,net.W)\n",
    "print(dW)\n",
    "# 損失関数をｈ倍→0.210ｈ増加\n",
    "# 　　　　　　　→0.343ｈ減少\n",
    "# つまり、+0.～は-ｈ倍、-0.～はh倍する\n",
    "# 一番影響力があるのは絶対値で一番大きい数値"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# まとめ\n",
    "# 学習アルゴリズムの実装方法(確率的勾配降下法→SGD)\n",
    "# ①ランダムに訓練データの中から一定数選び推論(ミニバッチ)→損失関数の取得\n",
    "# ②ミニバッチの損失関数を減らすために、重みの勾配をもとめ、損失関数の値を最も減らす方向を算出\n",
    "# ③重みを勾配方向に更新する(学習率)\n",
    "# ④①～③を繰り返す(ステップ数)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ２層ニューラルネットクラス\n",
    "class TwoLayerNet:\n",
    "# 初期化用コンストラクタ（自身、入力層ニューロンの数、隠れ層ニューロンの数、出力層ニューロンの数）\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "#  重みの初期化\n",
    "        self.params = {}\n",
    "# 値\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "# 推論メソッド(x:入力データ)\n",
    "    def predict(self, x):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "    \n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        return y\n",
    "\n",
    "# 認識精度メソッド(x:データ, t:教師データ)\n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "    \n",
    "# 損失関数取得メソッド(x:入力データ, t:教師データ)\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "#  交差エントロピー誤差メソッド(ｙ:推論、ｔ:教師)\n",
    "        return cross_entropy_error(y, t)\n",
    "        \n",
    "# 各パラメータの損失関数の勾配取得メソッド(x:データ, t:教師データ)\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "# 勾配\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "\n",
    "        return grads\n",
    "\n",
    "# 各パラメータ損失関数の勾配取得メソッド高速版(x:データ, t:教師データ)\n",
    "# 誤差逆伝播法\n",
    "    def gradient(self, x, t):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "        grads = {}\n",
    "        \n",
    "        batch_num = x.shape[0]\n",
    "        \n",
    "        # forward\n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        # backward\n",
    "        dy = (y - t) / batch_num\n",
    "        grads['W2'] = np.dot(z1.T, dy)\n",
    "        grads['b2'] = np.sum(dy, axis=0)\n",
    "        \n",
    "        dz1 = np.dot(dy, W2.T)\n",
    "        da1 = sigmoid_grad(a1) * dz1\n",
    "        grads['W1'] = np.dot(x.T, da1)\n",
    "        grads['b1'] = np.sum(da1, axis=0)\n",
    "\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ①の実施\n",
    "# データの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "# 入力画像が28*28、隠れ層は適当、出力層は0～9の10個\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "# ハイパーパラメータ\n",
    "iters_num = 10000 # 繰り返しの回数を適宜設定する\n",
    "train_size = x_train.shape[0]# 取得したデータの数\n",
    "batch_size = 100 # ミニバッチの値\n",
    "learning_rate = 0.1 # 学習率\n",
    "\n",
    "train_loss_list = [] # 損失関数の配列\n",
    "train_acc_list = [] # 訓練精度の配列\n",
    "test_acc_list = [] # 本番精度の配列\n",
    "# 1エポック当たりの繰り返し\n",
    "# エポック：10000個の訓練データを100個のミニバッチにすると100回確率的勾配降下法をやる→1エポック\n",
    "# それで認証精度を確認する→\n",
    "# 画像の数/ミニバッチの値+\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "for i in range(iters_num):\n",
    "#  ミニバッチの数で訓練データの要素をランダムに取得\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask] # 訓練用画像取得\n",
    "    t_batch = t_train[batch_mask] # 教師データ取得\n",
    "    \n",
    "# 勾配の計算\n",
    "    grad= network.numerical_gradient(x_batch, t_batch)\n",
    "#     grad = network.gradient(x_batch, t_batch)\n",
    "    \n",
    "# パラメータの更新\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "# 学習経過の記録\n",
    "        loss = network.loss(x_batch, t_batch)\n",
    "        train_loss_list.append(loss)\n",
    "# 1エポックごとに認識精度を計算    \n",
    "        if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"train acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))\n",
    "\n",
    "# 経過表示\n",
    "print(f\"[更新数]{i: >4} [損失関数の値]{loss:.4f} \"f\"[訓練データの認識精度]{train_acc:.4f} [テストデータの認識精度]{test_acc:.4f}\")\n",
    "\n",
    "# 損失関数の値の推移を描画\n",
    "x = np.arange(len(train_loss_list))\n",
    "plt.plot(x, train_loss_list, label='loss')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlim(left=0)\n",
    "plt.ylim(bottom=0)\n",
    "plt.show()\n",
    "\n",
    "# 訓練データとテストデータの認識精度の推移を描画\n",
    "x2 = np.arange(len(train_acc_list))\n",
    "plt.plot(x2, train_acc_list, label='train acc')\n",
    "plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlim(left=0)\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
